{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-FqwtTFaU8C"
      },
      "outputs": [],
      "source": [
        "## for data\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "## for plotting\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "## for statistical tests\n",
        "import scipy\n",
        "\n",
        "## for machine learning\n",
        "from sklearn import model_selection, preprocessing, feature_selection, ensemble, linear_model, metrics, decomposition\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, recall_score, precision_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import datasets\n",
        "import matplotlib.cm as cm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.loadtxt('/content/misterious_data_1_1.txt')\n",
        "#print(data[0])"
      ],
      "metadata": {
        "id": "w71iO2pVan5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_features = 153\n",
        "n_samples = 528\n",
        "\n",
        "x = np.empty((n_samples, n_features)) #data o features\n",
        "y = np.empty((n_samples,), dtype=int) #target\n",
        "\n",
        "with open('/content/misterious_data_1_1.txt', 'r') as file:\n",
        "    for i, line in enumerate(file):\n",
        "        values = line.strip().split('\\t')\n",
        "        y[i] = int(values[0]) -1\n",
        "        features = [float(value) for value in values[1:]]\n",
        "        x[i] = features"
      ],
      "metadata": {
        "id": "xulC0dQua8N7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "targets = ['1', '2']\n",
        "#print(y)\n",
        "#print(x)"
      ],
      "metadata": {
        "id": "CfEzR0k0hWzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_features = x.shape[1]\n",
        "n_targets = len(y)\n",
        "print(n_features)\n",
        "#print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WO2ic-dozCBM",
        "outputId": "0f3bac69-b4b5-4e09-ef27-e1a62e45402b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "153\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **EJERCICIO 1.1**"
      ],
      "metadata": {
        "id": "ft6jAlZ_YUx6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Neurona Perceptrón**"
      ],
      "metadata": {
        "id": "jl1vfthfp1Ua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def perceptron(x, w):\n",
        "  ws = sum(x*w)\n",
        "  yt = 0\n",
        "  if ws < 0:\n",
        "    yt = -1\n",
        "  elif ws > 0:\n",
        "    yt = 1\n",
        "\n",
        "  return yt"
      ],
      "metadata": {
        "id": "DX5pCkcLT27c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Función Multi-Perceptrón**"
      ],
      "metadata": {
        "id": "gQCL_Vihce3B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def perceptron_multi(x, w):\n",
        "  yp = []\n",
        "  for xi in x:\n",
        "    yp.append(perceptron(xi, w))\n",
        "  return np.array(yp)"
      ],
      "metadata": {
        "id": "_QRrRyNV2jZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import np_utils\n",
        "output_y = np_utils.to_categorical(y)\n",
        "print(output_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMhZ6jAqhmxw",
        "outputId": "43ad1a0c-57e1-40ac-fe24-70224a80188f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " ...\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Define MLP model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "clf = Sequential()\n",
        "clf.add(Dense(10, input_dim = n_features, activation = 'relu'))\n",
        "clf.add(Dense(10, activation = 'relu'))\n",
        "clf.add(Dense(1, activation = 'sigmoid'))"
      ],
      "metadata": {
        "id": "UyIanqy-34Wv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VHz21yg3nVBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhmz9eO3nVM0",
        "outputId": "9ea87ddd-4003-4d42-f957-5f556837d440"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(528, 153)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Compile model\n",
        "clf.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "\n",
        "#Fit model\n",
        "clf.fit(x, y, epochs = 100, batch_size = 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDFrbua47fO0",
        "outputId": "3c0735e1-c248-48ab-bbf4-ae65740804d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "106/106 [==============================] - 2s 2ms/step - loss: 0.6372 - accuracy: 0.6269\n",
            "Epoch 2/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7652\n",
            "Epoch 3/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.4079 - accuracy: 0.8314\n",
            "Epoch 4/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.3359 - accuracy: 0.8580\n",
            "Epoch 5/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.2804 - accuracy: 0.8845\n",
            "Epoch 6/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.2409 - accuracy: 0.9034\n",
            "Epoch 7/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.2098 - accuracy: 0.9205\n",
            "Epoch 8/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.1833 - accuracy: 0.9299\n",
            "Epoch 9/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.1659 - accuracy: 0.9375\n",
            "Epoch 10/100\n",
            "106/106 [==============================] - 0s 3ms/step - loss: 0.1434 - accuracy: 0.9527\n",
            "Epoch 11/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1281 - accuracy: 0.9640\n",
            "Epoch 12/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.1140 - accuracy: 0.9640\n",
            "Epoch 13/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0980 - accuracy: 0.9754\n",
            "Epoch 14/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0856 - accuracy: 0.9773\n",
            "Epoch 15/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0742 - accuracy: 0.9848\n",
            "Epoch 16/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0625 - accuracy: 0.9886\n",
            "Epoch 17/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0537 - accuracy: 0.9924\n",
            "Epoch 18/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0491 - accuracy: 0.9924\n",
            "Epoch 19/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0399 - accuracy: 0.9943\n",
            "Epoch 20/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0340 - accuracy: 0.9943\n",
            "Epoch 21/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0311 - accuracy: 0.9943\n",
            "Epoch 22/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0266 - accuracy: 0.9943\n",
            "Epoch 23/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0236 - accuracy: 0.9943\n",
            "Epoch 24/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0206 - accuracy: 0.9962\n",
            "Epoch 25/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0186 - accuracy: 0.9943\n",
            "Epoch 26/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0167 - accuracy: 0.9962\n",
            "Epoch 27/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0143 - accuracy: 0.9981\n",
            "Epoch 28/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0129 - accuracy: 0.9981\n",
            "Epoch 29/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0116 - accuracy: 1.0000\n",
            "Epoch 30/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0102 - accuracy: 1.0000\n",
            "Epoch 31/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0090 - accuracy: 1.0000\n",
            "Epoch 32/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0080 - accuracy: 1.0000\n",
            "Epoch 33/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0071 - accuracy: 1.0000\n",
            "Epoch 34/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0062 - accuracy: 1.0000\n",
            "Epoch 35/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0056 - accuracy: 1.0000\n",
            "Epoch 36/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0050 - accuracy: 1.0000\n",
            "Epoch 37/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0044 - accuracy: 1.0000\n",
            "Epoch 38/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0040 - accuracy: 1.0000\n",
            "Epoch 39/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0036 - accuracy: 1.0000\n",
            "Epoch 40/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "Epoch 41/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 1.0000\n",
            "Epoch 42/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 1.0000\n",
            "Epoch 43/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 1.0000\n",
            "Epoch 44/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000\n",
            "Epoch 45/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 46/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000\n",
            "Epoch 47/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 48/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 49/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000\n",
            "Epoch 50/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 51/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 52/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 53/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 54/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000\n",
            "Epoch 55/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 9.5861e-04 - accuracy: 1.0000\n",
            "Epoch 56/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 8.8718e-04 - accuracy: 1.0000\n",
            "Epoch 57/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 8.1191e-04 - accuracy: 1.0000\n",
            "Epoch 58/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 7.5726e-04 - accuracy: 1.0000\n",
            "Epoch 59/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 7.0145e-04 - accuracy: 1.0000\n",
            "Epoch 60/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 6.5356e-04 - accuracy: 1.0000\n",
            "Epoch 61/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 6.1940e-04 - accuracy: 1.0000\n",
            "Epoch 62/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 5.6518e-04 - accuracy: 1.0000\n",
            "Epoch 63/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 5.3047e-04 - accuracy: 1.0000\n",
            "Epoch 64/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 4.9507e-04 - accuracy: 1.0000\n",
            "Epoch 65/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 4.6798e-04 - accuracy: 1.0000\n",
            "Epoch 66/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 4.3876e-04 - accuracy: 1.0000\n",
            "Epoch 67/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 4.1093e-04 - accuracy: 1.0000\n",
            "Epoch 68/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 4.0451e-04 - accuracy: 1.0000\n",
            "Epoch 69/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 3.8988e-04 - accuracy: 1.0000\n",
            "Epoch 70/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 3.5787e-04 - accuracy: 1.0000\n",
            "Epoch 71/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 3.3159e-04 - accuracy: 1.0000\n",
            "Epoch 72/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 3.0847e-04 - accuracy: 1.0000\n",
            "Epoch 73/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 2.8887e-04 - accuracy: 1.0000\n",
            "Epoch 74/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 2.7003e-04 - accuracy: 1.0000\n",
            "Epoch 75/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 2.5560e-04 - accuracy: 1.0000\n",
            "Epoch 76/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 2.3891e-04 - accuracy: 1.0000\n",
            "Epoch 77/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 2.2584e-04 - accuracy: 1.0000\n",
            "Epoch 78/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 2.1284e-04 - accuracy: 1.0000\n",
            "Epoch 79/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 2.0056e-04 - accuracy: 1.0000\n",
            "Epoch 80/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 3.4873e-04 - accuracy: 1.0000\n",
            "Epoch 81/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 1.8296e-04 - accuracy: 1.0000\n",
            "Epoch 82/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 1.7100e-04 - accuracy: 1.0000\n",
            "Epoch 83/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 1.6144e-04 - accuracy: 1.0000\n",
            "Epoch 84/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 1.5613e-04 - accuracy: 1.0000\n",
            "Epoch 85/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 1.5363e-04 - accuracy: 1.0000\n",
            "Epoch 86/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 1.5126e-04 - accuracy: 1.0000\n",
            "Epoch 87/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 1.4181e-04 - accuracy: 1.0000\n",
            "Epoch 88/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 1.3088e-04 - accuracy: 1.0000\n",
            "Epoch 89/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 1.2155e-04 - accuracy: 1.0000\n",
            "Epoch 90/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 1.1401e-04 - accuracy: 1.0000\n",
            "Epoch 91/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 1.0751e-04 - accuracy: 1.0000\n",
            "Epoch 92/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 1.0117e-04 - accuracy: 1.0000\n",
            "Epoch 93/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 9.5251e-05 - accuracy: 1.0000\n",
            "Epoch 94/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 9.0096e-05 - accuracy: 1.0000\n",
            "Epoch 95/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 8.5158e-05 - accuracy: 1.0000\n",
            "Epoch 96/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 8.0720e-05 - accuracy: 1.0000\n",
            "Epoch 97/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 7.6387e-05 - accuracy: 1.0000\n",
            "Epoch 98/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 7.2131e-05 - accuracy: 1.0000\n",
            "Epoch 99/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 6.8586e-05 - accuracy: 1.0000\n",
            "Epoch 100/100\n",
            "106/106 [==============================] - 0s 2ms/step - loss: 6.4906e-05 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f63c9146dd0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cross validation con dos clases**"
      ],
      "metadata": {
        "id": "SbmThpDkrVuk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model\n",
        "from sklearn.model_selection import KFold\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.utils import np_utils\n",
        "\n",
        "kf = KFold(n_splits=5, shuffle = True)\n",
        "acc = 0\n",
        "recall = np.array([0., 0., 0.])\n",
        "\n",
        "for train_index, test_index in kf.split(x):\n",
        "\n",
        "  # Training phase\n",
        "  x_train = x[train_index, :]\n",
        "  y_train = y[train_index]\n",
        "\n",
        "  clf_cv = Sequential()\n",
        "  clf_cv.add(Dense(10, input_dim=n_features, activation='relu'))\n",
        "  clf_cv.add(Dense(10, activation='relu'))\n",
        "  clf_cv.add(Dense(1, activation='sigmoid'))\n",
        "  clf_cv.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "  clf_cv.fit(x_train, y_train, epochs=150, batch_size=15, verbose=0)\n",
        "\n",
        "  # Test phase\n",
        "  x_test = x[test_index, :]\n",
        "  y_test = y[test_index]\n",
        "  y_pred = (clf_cv.predict(x_test)>0.5).astype(\"int32\")\n",
        "\n",
        "  # Performance scores\n",
        "  acc += accuracy_score(y_test, y_pred)\n",
        "\n",
        "acc = acc/5\n",
        "print('ACC = ', acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iy3BCAi1sM5L",
        "outputId": "949e16e3-bcb5-41b3-e3f0-750b01fa2d71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "4/4 [==============================] - 0s 3ms/step\n",
            "ACC =  0.7708176100628931\n"
          ]
        }
      ]
    }
  ]
}