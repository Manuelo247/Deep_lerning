{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q3mcxU6Vv8i2"
      },
      "outputs": [],
      "source": [
        "## for data\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "## for plotting\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "## for statistical tests\n",
        "import scipy\n",
        "\n",
        "## for machine learning\n",
        "from sklearn import model_selection, preprocessing, feature_selection, ensemble, linear_model, metrics, decomposition\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, recall_score, precision_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import datasets\n",
        "import matplotlib.cm as cm\n",
        "\n",
        "#dataset\n",
        "from sklearn.datasets import load_wine"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wine = load_wine()"
      ],
      "metadata": {
        "id": "bgCSnCw_wE3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = wine.data\n",
        "y = wine.target"
      ],
      "metadata": {
        "id": "veESN6DnwIIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "targets = wine.target\n",
        "#print(targets)\n",
        "n_targets = len(targets)\n",
        "features = wine.feature_names\n",
        "n_features = len(features)\n",
        "print(n_targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7arh93e5wLaq",
        "outputId": "0b5259b2-410c-4f87-9463-d097665bd6a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "178\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Matriz de etiquetas en formato de text\n",
        "\n",
        "# Crear una instancia de LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Ajustar el codificador a las etiquetas de texto\n",
        "label_encoder.fit(y)\n",
        "\n",
        "# Transformar las etiquetas de texto a etiquetas numéricas\n",
        "etiquetas_numericas = label_encoder.transform(y)\n",
        "\n",
        "# Imprimir las etiquetas numéricas\n",
        "print(len(etiquetas_numericas))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZpoL8fduwPzP",
        "outputId": "bcbb49c0-5102-4fc9-fcfc-124e35a039bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "178\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neurona Perceptron"
      ],
      "metadata": {
        "id": "GXajFHLPwcIG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def perceptron(x, w):\n",
        "  ws = sum(x*w)\n",
        "  yt = 0\n",
        "  if ws < 0:\n",
        "    yt = -1\n",
        "  elif ws > 0:\n",
        "    yt = 1\n",
        "\n",
        "  return yt"
      ],
      "metadata": {
        "id": "InkREPlVwSDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Función Multi-perceptrón"
      ],
      "metadata": {
        "id": "PURgxd3Kwg6v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def perceptron_multi(x, w):\n",
        "  yp = []\n",
        "  for xi in x:\n",
        "    yp.append(perceptron(xi, w))\n",
        "  return np.array(yp)"
      ],
      "metadata": {
        "id": "7z9d5dagwlZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import np_utils\n",
        "output_y = np_utils.to_categorical(y)\n",
        "print(output_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBHlDkmJwoDD",
        "outputId": "29f1acb3-dfaf-4b7d-d99e-b791b5b18d1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]\n",
            " [0. 0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Define MLP model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.regularizers import l2\n",
        "\n",
        "clf = Sequential()\n",
        "clf.add(Dense(20, input_dim = n_features, activation = 'relu',kernel_regularizer=l2(100)))\n",
        "clf.add(Dense(20, activation = 'relu',kernel_regularizer=l2(100)))\n",
        "clf.add(Dense(20, activation = 'relu', kernel_regularizer=l2(100)))\n",
        "clf.add(Dense(20, activation = 'relu', kernel_regularizer=l2(100)))\n",
        "clf.add(Dense(20, activation = 'relu', kernel_regularizer=l2(100)))\n",
        "\n",
        "clf.add(Dense(3, activation = 'softmax'))"
      ],
      "metadata": {
        "id": "cROJPb0CwtB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Compile model\n",
        "clf.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "\n",
        "#Fit model\n",
        "clf.fit(x, output_y, epochs = 100, batch_size = 15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZSjx3_7wuCK",
        "outputId": "f7251772-eb85-42ae-d6ff-1b57945cd423"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "12/12 [==============================] - 2s 3ms/step - loss: 9198.9629 - accuracy: 0.3034\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 8374.1670 - accuracy: 0.2753\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 7613.0718 - accuracy: 0.2753\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 6915.3750 - accuracy: 0.2303\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 6277.1221 - accuracy: 0.2697\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 5693.8354 - accuracy: 0.2697\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 5160.8599 - accuracy: 0.2697\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 4673.9106 - accuracy: 0.2753\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 4229.1470 - accuracy: 0.2921\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3823.1184 - accuracy: 0.2697\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3452.6135 - accuracy: 0.2472\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 3114.7612 - accuracy: 0.3090\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2807.0203 - accuracy: 0.3427\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 2526.9648 - accuracy: 0.3933\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2272.2988 - accuracy: 0.3371\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 2040.9633 - accuracy: 0.1854\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1831.0549 - accuracy: 0.0955\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1640.7816 - accuracy: 0.0393\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1468.4987 - accuracy: 0.1011\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1312.6807 - accuracy: 0.1966\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1171.9188 - accuracy: 0.3034\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1044.9185 - accuracy: 0.3315\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 930.4780 - accuracy: 0.3315\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 827.4862 - accuracy: 0.3315\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 734.9218 - accuracy: 0.3315\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 651.8425 - accuracy: 0.3315\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 577.3802 - accuracy: 0.3315\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 510.7363 - accuracy: 0.3315\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 451.1746 - accuracy: 0.3315\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 398.0176 - accuracy: 0.3315\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 350.6452 - accuracy: 0.4101\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 308.4885 - accuracy: 0.3989\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 271.0299 - accuracy: 0.3989\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 237.7949 - accuracy: 0.3989\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 208.3515 - accuracy: 0.3989\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 182.3066 - accuracy: 0.3989\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 159.3026 - accuracy: 0.3989\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 139.0158 - accuracy: 0.3989\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 121.1526 - accuracy: 0.3989\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 105.4477 - accuracy: 0.3989\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 91.6619 - accuracy: 0.3989\n",
            "Epoch 42/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 79.5795 - accuracy: 0.3989\n",
            "Epoch 43/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 69.0067 - accuracy: 0.3989\n",
            "Epoch 44/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 59.7694 - accuracy: 0.3989\n",
            "Epoch 45/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 51.7112 - accuracy: 0.3989\n",
            "Epoch 46/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 44.6935 - accuracy: 0.3989\n",
            "Epoch 47/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 38.5911 - accuracy: 0.3989\n",
            "Epoch 48/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 33.2933 - accuracy: 0.3989\n",
            "Epoch 49/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 28.7015 - accuracy: 0.3989\n",
            "Epoch 50/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 24.7278 - accuracy: 0.3989\n",
            "Epoch 51/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 21.2948 - accuracy: 0.3989\n",
            "Epoch 52/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 18.3335 - accuracy: 0.3989\n",
            "Epoch 53/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 15.7831 - accuracy: 0.3989\n",
            "Epoch 54/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 13.5905 - accuracy: 0.3989\n",
            "Epoch 55/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 11.7083 - accuracy: 0.3989\n",
            "Epoch 56/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 10.0955 - accuracy: 0.3989\n",
            "Epoch 57/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 8.7152 - accuracy: 0.3989\n",
            "Epoch 58/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 7.5365 - accuracy: 0.3989\n",
            "Epoch 59/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 6.5312 - accuracy: 0.3989\n",
            "Epoch 60/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 5.6753 - accuracy: 0.3989\n",
            "Epoch 61/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 4.9478 - accuracy: 0.3989\n",
            "Epoch 62/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 4.3305 - accuracy: 0.3989\n",
            "Epoch 63/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.8075 - accuracy: 0.3989\n",
            "Epoch 64/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 3.3652 - accuracy: 0.3989\n",
            "Epoch 65/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.9917 - accuracy: 0.3989\n",
            "Epoch 66/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.6769 - accuracy: 0.3989\n",
            "Epoch 67/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.4119 - accuracy: 0.3989\n",
            "Epoch 68/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.1893 - accuracy: 0.3989\n",
            "Epoch 69/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 2.0026 - accuracy: 0.3989\n",
            "Epoch 70/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.8463 - accuracy: 0.3989\n",
            "Epoch 71/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.7155 - accuracy: 0.3989\n",
            "Epoch 72/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.6065 - accuracy: 0.3989\n",
            "Epoch 73/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.5156 - accuracy: 0.3989\n",
            "Epoch 74/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.4400 - accuracy: 0.3989\n",
            "Epoch 75/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.3773 - accuracy: 0.3989\n",
            "Epoch 76/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.3254 - accuracy: 0.3989\n",
            "Epoch 77/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.2822 - accuracy: 0.3989\n",
            "Epoch 78/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.2467 - accuracy: 0.3989\n",
            "Epoch 79/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.2174 - accuracy: 0.3989\n",
            "Epoch 80/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1931 - accuracy: 0.3989\n",
            "Epoch 81/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1733 - accuracy: 0.3989\n",
            "Epoch 82/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.1571 - accuracy: 0.3989\n",
            "Epoch 83/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1438 - accuracy: 0.3989\n",
            "Epoch 84/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1328 - accuracy: 0.3989\n",
            "Epoch 85/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.1239 - accuracy: 0.3989\n",
            "Epoch 86/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1166 - accuracy: 0.3989\n",
            "Epoch 87/100\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 1.1107 - accuracy: 0.3989\n",
            "Epoch 88/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1059 - accuracy: 0.3989\n",
            "Epoch 89/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.1020 - accuracy: 0.3989\n",
            "Epoch 90/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0988 - accuracy: 0.3989\n",
            "Epoch 91/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0963 - accuracy: 0.3989\n",
            "Epoch 92/100\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 1.0943 - accuracy: 0.3989\n",
            "Epoch 93/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0928 - accuracy: 0.3989\n",
            "Epoch 94/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0916 - accuracy: 0.3989\n",
            "Epoch 95/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0902 - accuracy: 0.3989\n",
            "Epoch 96/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0894 - accuracy: 0.3989\n",
            "Epoch 97/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0887 - accuracy: 0.3989\n",
            "Epoch 98/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0882 - accuracy: 0.3989\n",
            "Epoch 99/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0879 - accuracy: 0.3989\n",
            "Epoch 100/100\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.0874 - accuracy: 0.3989\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f178e002680>"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cross-Validation con tres clases\n"
      ],
      "metadata": {
        "id": "5nrWZ1LQw6IF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.utils import np_utils\n",
        "\n",
        "kf = StratifiedKFold(n_splits=5, shuffle = True)\n",
        "acc = 0\n",
        "recall = np.array([0., 0., 0.])\n",
        "\n",
        "for train_index, test_index in kf.split(x,y):\n",
        "\n",
        "  # Training phase\n",
        "  x_train, x_val = x[train_index], x[test_index]\n",
        "  y_train, y_val = y[train_index], y[test_index]\n",
        "\n",
        "  clf_cv = Sequential()\n",
        "  clf_cv.add(Dense(20, input_dim=n_features, activation='relu'))\n",
        "  clf_cv.add(Dense(20, activation='relu'))\n",
        "  clf_cv.add(Dense(20, activation='relu'))\n",
        "  clf_cv.add(Dense(20, activation='relu'))\n",
        "  clf_cv.add(Dense(20, activation='relu'))\n",
        "\n",
        "  clf_cv.add(Dense(3, activation='softmax'))\n",
        "  clf_cv.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "  y_train_encoded = np_utils.to_categorical(y_train)\n",
        "  y_val_encoded = np_utils.to_categorical(y_val)\n",
        "\n",
        "  clf_cv.fit(x_train, y_train_encoded, epochs=150, batch_size=15, verbose=0, validation_data=(x_val, y_val_encoded))\n",
        "\n",
        "  # Test phase\n",
        "  y_pred = np.argmax(clf_cv.predict(x_val), axis=1)\n",
        "\n",
        "  # Performance scores\n",
        "  acc += accuracy_score(y_val, y_pred)\n",
        "\n",
        "acc = acc/5\n",
        "print('ACC = ', acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZML-bI1wwwc",
        "outputId": "20120e85-7eaa-47c0-a87f-285179a912e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 12ms/step\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "ACC =  0.9326984126984128\n"
          ]
        }
      ]
    }
  ]
}